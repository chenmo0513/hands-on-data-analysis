## 第五节

获取数据——》数据预处理——》训练模型——》模型评估——》预测，分类。

更重要的是理解我们之前为什么要做特征处理，还可以进一步扩展到探索不同的模型需要怎样不同的特征处理~另外，模型的评估也是相当重要的部分，希望大家能够掌握教程中评估函数的意义和适用范围，在自己跑模型的时候，能够根据需要选用合适的评估函数

### 建模与评估

https://blog.csdn.net/weixin_55730631/article/details/121345121

tips 

```
plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签
plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号
plt.rcParams['figure.figsize'] = (10, 6)  # 设置输出图片大小
```



#### 

在进行模型选择之前我们需要先知道数据集最终是进行**监督学习**还是**无监督学习**

其中 **分类和回归**是监督式学习，即每个数据对应一个 label。 **聚类** 是非监督式学习，即没有 label。 另外一类是 **降维**，当数据集有很多很多属性的时候，可以通过 降维 算法把属性归纳起来。



模型的选择基于两方面， 一方面是任务，另外是样本量和特征稀疏性。

常用的回归：线性、决策树、SVM、KNN ；集成回归：随机森林、Adaboost、GradientBoosting、Bagging、ExtraTrees

常用的分类：线性、决策树、SVM、KNN，朴素贝叶斯；集成分类：随机森林、Adaboost、GradientBoosting、Bagging、ExtraTrees

常用聚类：k均值（K-means）、层次聚类（Hierarchical clustering）、DBSCAN

常用降维：LinearDiscriminantAnalysis、PCA

过程是确定一个基本baseline，然后训练其他模型对比，选择泛化能力或性能比较好的模型。

https://www.youtube.com/watch?v=QtBxBJQsI2A

#### 建模

#### 1. 划分训练集和测试集

##### Hold-out Method（留出法）

随机劈开，一个用于训练，一个是测试。

`**sklearn.model_selection.train_test_split****随机划分训练集和测试集**`

[`model_selection.train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split)

##### K-fold Cross-Validation(k折交叉验证法)：

大小相同的k个留出法，其中一个为测试，其余为训练

##### 自助法 bootstrap

重新构建数据集，可随机抽取构成新的集合训练集，其余未被抽取的数据为测试集

![img](E:\Desktop\validation.png)

https://moredvikas.wordpress.com/2018/10/10/machine-learning-model-validation-techniques/

[`model_selection.KFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold)

#### 2. 模型创建

基本可以使用`fit`、`predict`、`score`来训练、评价模型，并使用模型进行预测。

##### 训练模型

```python
lr = LogisticRegression() # 实例化
lr.fit(X_train, y_train) #训练模型
```

```py
rfc = RandomForestClassifier()
rfc.fit(X_train, y_train)
```

SVM 支持向量机

##### 评分

###### mean accuracy

确定模型训练结果与实际值对比

```
rfc2.score(X_train, y_train)
lr2.score(X_train, y_train)
```

###### F1  Scores

##### 调整

```
lr2 = LogisticRegression(C=100)
rfc2 = RandomForestClassifier(n_estimators=100, max_depth=5)
```

预测

```py
pred = lr.predict(X_train)

```

输出模型预测结果

完事了？？

